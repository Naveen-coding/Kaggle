{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "important-friend",
   "metadata": {},
   "source": [
    "# Problem statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appreciated-outline",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Context\n",
    "The SMS Spam Collection is a set of SMS tagged messages that have been collected for SMS Spam research. It contains one set of SMS messages in English of 5,574 messages, tagged acording being ham (legitimate) or spam.\n",
    "\n",
    "Content\n",
    "The files contain one message per line. Each line is composed by two columns: v1 contains the label (ham or spam) and v2 contains the raw text.\n",
    "\n",
    "This corpus has been collected from free or free for research sources at the Internet:\n",
    "\n",
    "-> A collection of 425 SMS spam messages was manually extracted from the Grumbletext Web site. This is a UK forum in which cell phone users make public claims about SMS spam messages, most of them without reporting the very spam message received. The identification of the text of spam messages in the claims is a very hard and time-consuming task, and it involved carefully scanning hundreds of web pages. The Grumbletext Web site is: [Web Link].\n",
    "-> A subset of 3,375 SMS randomly chosen ham messages of the NUS SMS Corpus (NSC), which is a dataset of about 10,000 legitimate messages collected for research at the Department of Computer Science at the National University of Singapore. The messages largely originate from Singaporeans and mostly from students attending the University. These messages were collected from volunteers who were made aware that their contributions were going to be made publicly available. The NUS SMS Corpus is avalaible at: [Web Link].\n",
    "-> A list of 450 SMS ham messages collected from Caroline Tag's PhD Thesis available at [Web Link].\n",
    "-> Finally, we have incorporated the SMS Spam Corpus v.0.1 Big. It has 1,002 SMS ham messages and 322 spam messages and it is public available at: [Web Link]. This corpus has been used in the following academic researches:\n",
    "\n",
    "Acknowledgements\n",
    "The original dataset can be found here. The creators would like to note that in case you find the dataset useful, please make a reference to previous paper and the web page: http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/ in your papers, research, etc.\n",
    "\n",
    "We offer a comprehensive study of this corpus in the following paper. This work presents a number of statistics, studies and baseline results for several machine learning methods.\n",
    "\n",
    "Almeida, T.A., GÃ³mez Hidalgo, J.M., Yamakami, A. Contributions to the Study of SMS Spam Filtering: New Collection and Results. Proceedings of the 2011 ACM Symposium on Document Engineering (DOCENG'11), Mountain View, CA, USA, 2011.\n",
    "\n",
    "Inspiration\n",
    "Can you use this dataset to build a prediction model that will accurately classify which texts are spam?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mexican-edgar",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "endless-pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colored-anaheim",
   "metadata": {},
   "source": [
    "# Data Insepction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "tracked-creek",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data = pd.read_csv('spam.csv',encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "confused-dragon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        v1                                                 v2 Unnamed: 2  \\\n",
       "0      ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1      ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3      ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "...    ...                                                ...        ...   \n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...        NaN   \n",
       "5568   ham              Will Ì_ b going to esplanade fr home?        NaN   \n",
       "5569   ham  Pity, * was in mood for that. So...any other s...        NaN   \n",
       "5570   ham  The guy did some bitching but I acted like i'd...        NaN   \n",
       "5571   ham                         Rofl. Its true to its name        NaN   \n",
       "\n",
       "     Unnamed: 3 Unnamed: 4  \n",
       "0           NaN        NaN  \n",
       "1           NaN        NaN  \n",
       "2           NaN        NaN  \n",
       "3           NaN        NaN  \n",
       "4           NaN        NaN  \n",
       "...         ...        ...  \n",
       "5567        NaN        NaN  \n",
       "5568        NaN        NaN  \n",
       "5569        NaN        NaN  \n",
       "5570        NaN        NaN  \n",
       "5571        NaN        NaN  \n",
       "\n",
       "[5572 rows x 5 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "aggressive-logistics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: v1, dtype: int64"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data[\"v1\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "pleased-overhead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     86.593683\n",
       "spam    13.406317\n",
       "Name: v1, dtype: float64"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data[\"v1\"].value_counts()/user_data.shape[0]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "instructional-oxford",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data.drop(labels=user_data[[\"Unnamed: 2\",\"Unnamed: 3\",\"Unnamed: 4\"]],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "optical-lounge",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data = user_data.rename(columns={'v1':'label','v2':'text'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "chicken-highway",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham              Will Ì_ b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "confident-calibration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5572"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data['text'].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "polar-equation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label    0\n",
       "text     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "differential-missile",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   label   5572 non-null   object\n",
      " 1   text    5572 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.2+ KB\n"
     ]
    }
   ],
   "source": [
    "user_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "vertical-selection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5572</td>\n",
       "      <td>5572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>5169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4825</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                    text\n",
       "count   5572                    5572\n",
       "unique     2                    5169\n",
       "top      ham  Sorry, I'll call later\n",
       "freq    4825                      30"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "joint-belle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label    object\n",
       "text     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "environmental-jurisdiction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text  text_length\n",
       "0   ham  Go until jurong point, crazy.. Available only ...           20\n",
       "1   ham                      Ok lar... Joking wif u oni...            6\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...           28\n",
       "3   ham  U dun say so early hor... U c already then say...           11\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...           13"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data['text_length'] = user_data['text'].apply(lambda x: len(x.split(' ')))\n",
    "user_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "familiar-segment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(user_data['text_length'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "velvet-baseball",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "streaming-input",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "user_data[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "careful-girlfriend",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\naveen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\seaborn\\_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='label', ylabel='count'>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(user_data[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interpreted-facial",
   "metadata": {},
   "source": [
    "# Text PreProcessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grateful-indian",
   "metadata": {},
   "source": [
    "### Removing Punctuations,Numbers and Specaial Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "educated-boutique",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(text):\n",
    "    clean_text = re.sub('[^A-Za-z]+',\" \",text)\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "copyrighted-shopper",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data['text_clean'] = user_data['text'].apply(lambda text : data_cleaning(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "tribal-peter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>text_length</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>20</td>\n",
       "      <td>Go until jurong point crazy Available only in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>6</td>\n",
       "      <td>Ok lar Joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>28</td>\n",
       "      <td>Free entry in a wkly comp to win FA Cup final ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>11</td>\n",
       "      <td>U dun say so early hor U c already then say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>13</td>\n",
       "      <td>Nah I don t think he goes to usf he lives arou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>30</td>\n",
       "      <td>This is the nd time we have tried contact u U ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "      <td>8</td>\n",
       "      <td>Will b going to esplanade fr home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>10</td>\n",
       "      <td>Pity was in mood for that So any other suggest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>26</td>\n",
       "      <td>The guy did some bitching but I acted like i d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>6</td>\n",
       "      <td>Rofl Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text  text_length  \\\n",
       "0      ham  Go until jurong point, crazy.. Available only ...           20   \n",
       "1      ham                      Ok lar... Joking wif u oni...            6   \n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...           28   \n",
       "3      ham  U dun say so early hor... U c already then say...           11   \n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...           13   \n",
       "...    ...                                                ...          ...   \n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...           30   \n",
       "5568   ham              Will Ì_ b going to esplanade fr home?            8   \n",
       "5569   ham  Pity, * was in mood for that. So...any other s...           10   \n",
       "5570   ham  The guy did some bitching but I acted like i'd...           26   \n",
       "5571   ham                         Rofl. Its true to its name            6   \n",
       "\n",
       "                                             text_clean  \n",
       "0     Go until jurong point crazy Available only in ...  \n",
       "1                              Ok lar Joking wif u oni   \n",
       "2     Free entry in a wkly comp to win FA Cup final ...  \n",
       "3          U dun say so early hor U c already then say   \n",
       "4     Nah I don t think he goes to usf he lives arou...  \n",
       "...                                                 ...  \n",
       "5567  This is the nd time we have tried contact u U ...  \n",
       "5568                 Will b going to esplanade fr home   \n",
       "5569  Pity was in mood for that So any other suggest...  \n",
       "5570  The guy did some bitching but I acted like i d...  \n",
       "5571                          Rofl Its true to its name  \n",
       "\n",
       "[5572 rows x 4 columns]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "complex-point",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data['text_lower'] = user_data['text'].apply(lambda text: data_cleaning(text).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "informational-duncan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>text_length</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>text_lower</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>20</td>\n",
       "      <td>Go until jurong point crazy Available only in ...</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>6</td>\n",
       "      <td>Ok lar Joking wif u oni</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>28</td>\n",
       "      <td>Free entry in a wkly comp to win FA Cup final ...</td>\n",
       "      <td>free entry in a wkly comp to win fa cup final ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>11</td>\n",
       "      <td>U dun say so early hor U c already then say</td>\n",
       "      <td>u dun say so early hor u c already then say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>13</td>\n",
       "      <td>Nah I don t think he goes to usf he lives arou...</td>\n",
       "      <td>nah i don t think he goes to usf he lives arou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>30</td>\n",
       "      <td>This is the nd time we have tried contact u U ...</td>\n",
       "      <td>this is the nd time we have tried contact u u ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "      <td>8</td>\n",
       "      <td>Will b going to esplanade fr home</td>\n",
       "      <td>will b going to esplanade fr home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>10</td>\n",
       "      <td>Pity was in mood for that So any other suggest...</td>\n",
       "      <td>pity was in mood for that so any other suggest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>26</td>\n",
       "      <td>The guy did some bitching but I acted like i d...</td>\n",
       "      <td>the guy did some bitching but i acted like i d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>6</td>\n",
       "      <td>Rofl Its true to its name</td>\n",
       "      <td>rofl its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text  text_length  \\\n",
       "0      ham  Go until jurong point, crazy.. Available only ...           20   \n",
       "1      ham                      Ok lar... Joking wif u oni...            6   \n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...           28   \n",
       "3      ham  U dun say so early hor... U c already then say...           11   \n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...           13   \n",
       "...    ...                                                ...          ...   \n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...           30   \n",
       "5568   ham              Will Ì_ b going to esplanade fr home?            8   \n",
       "5569   ham  Pity, * was in mood for that. So...any other s...           10   \n",
       "5570   ham  The guy did some bitching but I acted like i'd...           26   \n",
       "5571   ham                         Rofl. Its true to its name            6   \n",
       "\n",
       "                                             text_clean  \\\n",
       "0     Go until jurong point crazy Available only in ...   \n",
       "1                              Ok lar Joking wif u oni    \n",
       "2     Free entry in a wkly comp to win FA Cup final ...   \n",
       "3          U dun say so early hor U c already then say    \n",
       "4     Nah I don t think he goes to usf he lives arou...   \n",
       "...                                                 ...   \n",
       "5567  This is the nd time we have tried contact u U ...   \n",
       "5568                 Will b going to esplanade fr home    \n",
       "5569  Pity was in mood for that So any other suggest...   \n",
       "5570  The guy did some bitching but I acted like i d...   \n",
       "5571                          Rofl Its true to its name   \n",
       "\n",
       "                                             text_lower  \n",
       "0     go until jurong point crazy available only in ...  \n",
       "1                              ok lar joking wif u oni   \n",
       "2     free entry in a wkly comp to win fa cup final ...  \n",
       "3          u dun say so early hor u c already then say   \n",
       "4     nah i don t think he goes to usf he lives arou...  \n",
       "...                                                 ...  \n",
       "5567  this is the nd time we have tried contact u u ...  \n",
       "5568                 will b going to esplanade fr home   \n",
       "5569  pity was in mood for that so any other suggest...  \n",
       "5570  the guy did some bitching but i acted like i d...  \n",
       "5571                          rofl its true to its name  \n",
       "\n",
       "[5572 rows x 5 columns]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worth-twins",
   "metadata": {},
   "source": [
    "#### Removal of stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "happy-wallet",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Naveen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "julian-planning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "consecutive-poetry",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "more_stopwords = ['u', 'im', 'c']\n",
    "stop_words = stop_words + more_stopwords\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    text = ' '.join(word for word in text.split(' ') if word not in stop_words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "applied-belief",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data['text_remove_stopwards'] = user_data['text_lower'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "certain-flashing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>text_length</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>text_lower</th>\n",
       "      <th>text_remove_stopwards</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>20</td>\n",
       "      <td>Go until jurong point crazy Available only in ...</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>6</td>\n",
       "      <td>Ok lar Joking wif u oni</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "      <td>ok lar joking wif oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>28</td>\n",
       "      <td>Free entry in a wkly comp to win FA Cup final ...</td>\n",
       "      <td>free entry in a wkly comp to win fa cup final ...</td>\n",
       "      <td>free entry wkly comp win fa cup final tkts st ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>11</td>\n",
       "      <td>U dun say so early hor U c already then say</td>\n",
       "      <td>u dun say so early hor u c already then say</td>\n",
       "      <td>dun say early hor already say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>13</td>\n",
       "      <td>Nah I don t think he goes to usf he lives arou...</td>\n",
       "      <td>nah i don t think he goes to usf he lives arou...</td>\n",
       "      <td>nah think goes usf lives around though</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>30</td>\n",
       "      <td>This is the nd time we have tried contact u U ...</td>\n",
       "      <td>this is the nd time we have tried contact u u ...</td>\n",
       "      <td>nd time tried contact pound prize claim easy c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "      <td>8</td>\n",
       "      <td>Will b going to esplanade fr home</td>\n",
       "      <td>will b going to esplanade fr home</td>\n",
       "      <td>b going esplanade fr home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>10</td>\n",
       "      <td>Pity was in mood for that So any other suggest...</td>\n",
       "      <td>pity was in mood for that so any other suggest...</td>\n",
       "      <td>pity mood suggestions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>26</td>\n",
       "      <td>The guy did some bitching but I acted like i d...</td>\n",
       "      <td>the guy did some bitching but i acted like i d...</td>\n",
       "      <td>guy bitching acted like interested buying some...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>6</td>\n",
       "      <td>Rofl Its true to its name</td>\n",
       "      <td>rofl its true to its name</td>\n",
       "      <td>rofl true name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text  text_length  \\\n",
       "0      ham  Go until jurong point, crazy.. Available only ...           20   \n",
       "1      ham                      Ok lar... Joking wif u oni...            6   \n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...           28   \n",
       "3      ham  U dun say so early hor... U c already then say...           11   \n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...           13   \n",
       "...    ...                                                ...          ...   \n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...           30   \n",
       "5568   ham              Will Ì_ b going to esplanade fr home?            8   \n",
       "5569   ham  Pity, * was in mood for that. So...any other s...           10   \n",
       "5570   ham  The guy did some bitching but I acted like i'd...           26   \n",
       "5571   ham                         Rofl. Its true to its name            6   \n",
       "\n",
       "                                             text_clean  \\\n",
       "0     Go until jurong point crazy Available only in ...   \n",
       "1                              Ok lar Joking wif u oni    \n",
       "2     Free entry in a wkly comp to win FA Cup final ...   \n",
       "3          U dun say so early hor U c already then say    \n",
       "4     Nah I don t think he goes to usf he lives arou...   \n",
       "...                                                 ...   \n",
       "5567  This is the nd time we have tried contact u U ...   \n",
       "5568                 Will b going to esplanade fr home    \n",
       "5569  Pity was in mood for that So any other suggest...   \n",
       "5570  The guy did some bitching but I acted like i d...   \n",
       "5571                          Rofl Its true to its name   \n",
       "\n",
       "                                             text_lower  \\\n",
       "0     go until jurong point crazy available only in ...   \n",
       "1                              ok lar joking wif u oni    \n",
       "2     free entry in a wkly comp to win fa cup final ...   \n",
       "3          u dun say so early hor u c already then say    \n",
       "4     nah i don t think he goes to usf he lives arou...   \n",
       "...                                                 ...   \n",
       "5567  this is the nd time we have tried contact u u ...   \n",
       "5568                 will b going to esplanade fr home    \n",
       "5569  pity was in mood for that so any other suggest...   \n",
       "5570  the guy did some bitching but i acted like i d...   \n",
       "5571                          rofl its true to its name   \n",
       "\n",
       "                                  text_remove_stopwards  \n",
       "0     go jurong point crazy available bugis n great ...  \n",
       "1                                ok lar joking wif oni   \n",
       "2     free entry wkly comp win fa cup final tkts st ...  \n",
       "3                        dun say early hor already say   \n",
       "4                nah think goes usf lives around though  \n",
       "...                                                 ...  \n",
       "5567  nd time tried contact pound prize claim easy c...  \n",
       "5568                         b going esplanade fr home   \n",
       "5569                             pity mood suggestions   \n",
       "5570  guy bitching acted like interested buying some...  \n",
       "5571                                     rofl true name  \n",
       "\n",
       "[5572 rows x 6 columns]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-swing",
   "metadata": {},
   "source": [
    "# Text Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protecting-framing",
   "metadata": {},
   "source": [
    "#### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "lovely-print",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = nltk.SnowballStemmer(\"english\")\n",
    "\n",
    "def stemm_text(text):\n",
    "    text = ' '.join(stemmer.stem(word) for word in text.split(' '))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "skilled-democrat",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data['Stemming'] = user_data['text_remove_stopwards'].apply(stemm_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "statewide-meter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>text_length</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>text_lower</th>\n",
       "      <th>text_remove_stopwards</th>\n",
       "      <th>Stemming</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>20</td>\n",
       "      <td>Go until jurong point crazy Available only in ...</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "      <td>go jurong point crazi avail bugi n great world...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>6</td>\n",
       "      <td>Ok lar Joking wif u oni</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "      <td>ok lar joking wif oni</td>\n",
       "      <td>ok lar joke wif oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>28</td>\n",
       "      <td>Free entry in a wkly comp to win FA Cup final ...</td>\n",
       "      <td>free entry in a wkly comp to win fa cup final ...</td>\n",
       "      <td>free entry wkly comp win fa cup final tkts st ...</td>\n",
       "      <td>free entri wkli comp win fa cup final tkts st ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>11</td>\n",
       "      <td>U dun say so early hor U c already then say</td>\n",
       "      <td>u dun say so early hor u c already then say</td>\n",
       "      <td>dun say early hor already say</td>\n",
       "      <td>dun say earli hor alreadi say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>13</td>\n",
       "      <td>Nah I don t think he goes to usf he lives arou...</td>\n",
       "      <td>nah i don t think he goes to usf he lives arou...</td>\n",
       "      <td>nah think goes usf lives around though</td>\n",
       "      <td>nah think goe usf live around though</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>30</td>\n",
       "      <td>This is the nd time we have tried contact u U ...</td>\n",
       "      <td>this is the nd time we have tried contact u u ...</td>\n",
       "      <td>nd time tried contact pound prize claim easy c...</td>\n",
       "      <td>nd time tri contact pound prize claim easi cal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "      <td>8</td>\n",
       "      <td>Will b going to esplanade fr home</td>\n",
       "      <td>will b going to esplanade fr home</td>\n",
       "      <td>b going esplanade fr home</td>\n",
       "      <td>b go esplanad fr home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>10</td>\n",
       "      <td>Pity was in mood for that So any other suggest...</td>\n",
       "      <td>pity was in mood for that so any other suggest...</td>\n",
       "      <td>pity mood suggestions</td>\n",
       "      <td>piti mood suggest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>26</td>\n",
       "      <td>The guy did some bitching but I acted like i d...</td>\n",
       "      <td>the guy did some bitching but i acted like i d...</td>\n",
       "      <td>guy bitching acted like interested buying some...</td>\n",
       "      <td>guy bitch act like interest buy someth els nex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>6</td>\n",
       "      <td>Rofl Its true to its name</td>\n",
       "      <td>rofl its true to its name</td>\n",
       "      <td>rofl true name</td>\n",
       "      <td>rofl true name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text  text_length  \\\n",
       "0      ham  Go until jurong point, crazy.. Available only ...           20   \n",
       "1      ham                      Ok lar... Joking wif u oni...            6   \n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...           28   \n",
       "3      ham  U dun say so early hor... U c already then say...           11   \n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...           13   \n",
       "...    ...                                                ...          ...   \n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...           30   \n",
       "5568   ham              Will Ì_ b going to esplanade fr home?            8   \n",
       "5569   ham  Pity, * was in mood for that. So...any other s...           10   \n",
       "5570   ham  The guy did some bitching but I acted like i'd...           26   \n",
       "5571   ham                         Rofl. Its true to its name            6   \n",
       "\n",
       "                                             text_clean  \\\n",
       "0     Go until jurong point crazy Available only in ...   \n",
       "1                              Ok lar Joking wif u oni    \n",
       "2     Free entry in a wkly comp to win FA Cup final ...   \n",
       "3          U dun say so early hor U c already then say    \n",
       "4     Nah I don t think he goes to usf he lives arou...   \n",
       "...                                                 ...   \n",
       "5567  This is the nd time we have tried contact u U ...   \n",
       "5568                 Will b going to esplanade fr home    \n",
       "5569  Pity was in mood for that So any other suggest...   \n",
       "5570  The guy did some bitching but I acted like i d...   \n",
       "5571                          Rofl Its true to its name   \n",
       "\n",
       "                                             text_lower  \\\n",
       "0     go until jurong point crazy available only in ...   \n",
       "1                              ok lar joking wif u oni    \n",
       "2     free entry in a wkly comp to win fa cup final ...   \n",
       "3          u dun say so early hor u c already then say    \n",
       "4     nah i don t think he goes to usf he lives arou...   \n",
       "...                                                 ...   \n",
       "5567  this is the nd time we have tried contact u u ...   \n",
       "5568                 will b going to esplanade fr home    \n",
       "5569  pity was in mood for that so any other suggest...   \n",
       "5570  the guy did some bitching but i acted like i d...   \n",
       "5571                          rofl its true to its name   \n",
       "\n",
       "                                  text_remove_stopwards  \\\n",
       "0     go jurong point crazy available bugis n great ...   \n",
       "1                                ok lar joking wif oni    \n",
       "2     free entry wkly comp win fa cup final tkts st ...   \n",
       "3                        dun say early hor already say    \n",
       "4                nah think goes usf lives around though   \n",
       "...                                                 ...   \n",
       "5567  nd time tried contact pound prize claim easy c...   \n",
       "5568                         b going esplanade fr home    \n",
       "5569                             pity mood suggestions    \n",
       "5570  guy bitching acted like interested buying some...   \n",
       "5571                                     rofl true name   \n",
       "\n",
       "                                               Stemming  \n",
       "0     go jurong point crazi avail bugi n great world...  \n",
       "1                                  ok lar joke wif oni   \n",
       "2     free entri wkli comp win fa cup final tkts st ...  \n",
       "3                        dun say earli hor alreadi say   \n",
       "4                  nah think goe usf live around though  \n",
       "...                                                 ...  \n",
       "5567  nd time tri contact pound prize claim easi cal...  \n",
       "5568                             b go esplanad fr home   \n",
       "5569                                 piti mood suggest   \n",
       "5570  guy bitch act like interest buy someth els nex...  \n",
       "5571                                     rofl true name  \n",
       "\n",
       "[5572 rows x 7 columns]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outside-wallet",
   "metadata": {},
   "source": [
    "# Text Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuck-scratch",
   "metadata": {},
   "source": [
    "### Target Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "relevant-tragedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(user_data['label'])\n",
    "\n",
    "user_data['target_encoded'] = le.transform(user_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "explicit-sense",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>text_length</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>text_lower</th>\n",
       "      <th>text_remove_stopwards</th>\n",
       "      <th>Stemming</th>\n",
       "      <th>target_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>20</td>\n",
       "      <td>Go until jurong point crazy Available only in ...</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "      <td>go jurong point crazi avail bugi n great world...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>6</td>\n",
       "      <td>Ok lar Joking wif u oni</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "      <td>ok lar joking wif oni</td>\n",
       "      <td>ok lar joke wif oni</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>28</td>\n",
       "      <td>Free entry in a wkly comp to win FA Cup final ...</td>\n",
       "      <td>free entry in a wkly comp to win fa cup final ...</td>\n",
       "      <td>free entry wkly comp win fa cup final tkts st ...</td>\n",
       "      <td>free entri wkli comp win fa cup final tkts st ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>11</td>\n",
       "      <td>U dun say so early hor U c already then say</td>\n",
       "      <td>u dun say so early hor u c already then say</td>\n",
       "      <td>dun say early hor already say</td>\n",
       "      <td>dun say earli hor alreadi say</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>13</td>\n",
       "      <td>Nah I don t think he goes to usf he lives arou...</td>\n",
       "      <td>nah i don t think he goes to usf he lives arou...</td>\n",
       "      <td>nah think goes usf lives around though</td>\n",
       "      <td>nah think goe usf live around though</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text  text_length  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...           20   \n",
       "1   ham                      Ok lar... Joking wif u oni...            6   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...           28   \n",
       "3   ham  U dun say so early hor... U c already then say...           11   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...           13   \n",
       "\n",
       "                                          text_clean  \\\n",
       "0  Go until jurong point crazy Available only in ...   \n",
       "1                           Ok lar Joking wif u oni    \n",
       "2  Free entry in a wkly comp to win FA Cup final ...   \n",
       "3       U dun say so early hor U c already then say    \n",
       "4  Nah I don t think he goes to usf he lives arou...   \n",
       "\n",
       "                                          text_lower  \\\n",
       "0  go until jurong point crazy available only in ...   \n",
       "1                           ok lar joking wif u oni    \n",
       "2  free entry in a wkly comp to win fa cup final ...   \n",
       "3       u dun say so early hor u c already then say    \n",
       "4  nah i don t think he goes to usf he lives arou...   \n",
       "\n",
       "                               text_remove_stopwards  \\\n",
       "0  go jurong point crazy available bugis n great ...   \n",
       "1                             ok lar joking wif oni    \n",
       "2  free entry wkly comp win fa cup final tkts st ...   \n",
       "3                     dun say early hor already say    \n",
       "4             nah think goes usf lives around though   \n",
       "\n",
       "                                            Stemming  target_encoded  \n",
       "0  go jurong point crazi avail bugi n great world...               0  \n",
       "1                               ok lar joke wif oni                0  \n",
       "2  free entri wkli comp win fa cup final tkts st ...               1  \n",
       "3                     dun say earli hor alreadi say                0  \n",
       "4               nah think goe usf live around though               0  "
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operating-parallel",
   "metadata": {},
   "source": [
    "### Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "yellow-package",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 6216)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "review_vectorizer = CountVectorizer()\n",
    "\n",
    "review_features  =  review_vectorizer.fit_transform(user_data['Stemming'])\n",
    "review_features.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "distributed-chart",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5572x6216 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 44756 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "fewer-payment",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = review_features\n",
    "y = user_data['target_encoded'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "smaller-rochester",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5572x6216 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 44756 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "static-albany",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       1\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "5567    1\n",
       "5568    0\n",
       "5569    0\n",
       "5570    0\n",
       "5571    0\n",
       "Name: target_encoded, Length: 5572, dtype: int32"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "theoretical-tribune",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state = 47, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loved-baseline",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valuable-superintendent",
   "metadata": {},
   "source": [
    "## Decison Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "harmful-farming",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9605168700646087"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "model = tree.DecisionTreeClassifier(random_state=1)\n",
    "model.fit(x_train,y_train)\n",
    "pred= model.predict(x_test)\n",
    "\n",
    "from sklearn import metrics as m\n",
    "# Accuracy\n",
    "acc= m.accuracy_score(y_test,pred)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annual-market",
   "metadata": {},
   "source": [
    "## Navies bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "coastal-organization",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9712849964106246"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB()\n",
    "model.fit(x_train,y_train)\n",
    "pred= model.predict(x_test)\n",
    "\n",
    "from sklearn import metrics as m\n",
    "# Accuracy\n",
    "acc= m.accuracy_score(y_test,pred)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constitutional-somerset",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "secure-corrections",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9763101220387652"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train,y_train)\n",
    "pred= model.predict(x_test)\n",
    "\n",
    "from sklearn import metrics as m\n",
    "# Accuracy\n",
    "acc= m.accuracy_score(y_test,pred)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conventional-zambia",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "permanent-organization",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9741564967695621"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC()\n",
    "model.fit(x_train,y_train)\n",
    "pred= model.predict(x_test)\n",
    "\n",
    "from sklearn import metrics as m\n",
    "# Accuracy\n",
    "acc= m.accuracy_score(y_test,pred)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governmental-machine",
   "metadata": {},
   "source": [
    "## XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "affected-tradition",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Naveen\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:22:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9475951184493898"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "model=xgb.XGBClassifier(random_state=1,learning_rate=0.01)\n",
    "model.fit(x_train,y_train)\n",
    "pred= model.predict(x_test)\n",
    "\n",
    "from sklearn import metrics as m\n",
    "# Accuracy\n",
    "acc= m.accuracy_score(y_test,pred)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuck-fusion",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pediatric-corner",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "model = RandomForestClassifier(n_estimators= 700)\n",
    "model.fit(x_train,y_train)\n",
    "pred= model.predict(x_test)\n",
    "\n",
    "from sklearn import metrics as m\n",
    "# Accuracy\n",
    "acc= m.accuracy_score(y_test,pred)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yellow-template",
   "metadata": {},
   "source": [
    "## Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "elementary-tsunami",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9655419956927495"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "model=AdaBoostClassifier(random_state = 42)\n",
    "model.fit(x_train,y_train,)\n",
    "pred=model.predict(x_test)\n",
    "from sklearn import metrics as m\n",
    "acc=m.accuracy_score(y_test,pred)\n",
    "acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
